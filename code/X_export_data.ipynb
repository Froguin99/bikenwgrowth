{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra notebook - Exporting graphs and data for external visualization, further calculations\n",
    "## Project: Growing Urban Bicycle Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a temporary notebook which was needed to export data for creating the growbike.net platform. It takes the produced graphs or data from previous steps and exports the data in a format in which it can be used in an external visualization, or for further calculations. \n",
    "\n",
    "Contact: Michael Szell (michael.szell@gmail.com)  \n",
    "Created: 2020-09-25  \n",
    "Last modified: 2021-06-26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "debug = False # If True, will produce plots and/or verbose output to double-check\n",
    "%run -i \"../parameters/parameters.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PATH.\n",
      "\n",
      "Setup finished.\n",
      "\n",
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.6\n",
      "IPython version      : 8.27.0\n",
      "\n",
      "Compiler    : MSC v.1941 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 140 Stepping 1, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 19e8d1dcd8a92936e90ccacb37142aa1f2c65fdd\n",
      "\n",
      "IPython   : 8.27.0\n",
      "matplotlib: 3.8.4\n",
      "igraph    : 0.11.6\n",
      "csv       : 1.0\n",
      "geojson   : 3.1.0\n",
      "networkx  : 3.3\n",
      "numpy     : 1.26.4\n",
      "shapely   : 2.0.6\n",
      "geopandas : 0.14.4\n",
      "watermark : 2.5.0\n",
      "osmnx     : 1.9.4\n",
      "haversine : 2.8.1\n",
      "json      : 2.0.9\n",
      "pandas    : 2.2.3\n",
      "tqdm      : 4.66.5\n",
      "pyproj    : 3.6.1\n",
      "osgeo     : 3.9.2\n",
      "fiona     : 1.10.1\n",
      "sys       : 3.12.6 | packaged by conda-forge | (main, Sep 22 2024, 14:01:26) [MSC v.1941 64 bit (AMD64)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i path.py\n",
    "%run -i setup.py\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded functions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all parameter sets\n",
    "poi_source_list = [\n",
    "                    \"grid\", \n",
    "                   \"railwaystation\", \n",
    "                   \"neighbourhoods\"\n",
    "                   ]\n",
    "prune_measure_list = [\"betweenness\", \"closeness\", \"random\"]\n",
    "combs = list(itertools.product(poi_source_list, prune_measure_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Igraph to GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edited to avoid stopping if all types of parameters haven't been run yet - 09 Oct 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151586fa56ec4499905bcdcd20e98554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cities:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newcastle: Exporting streets to GeoJSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b8008458\\OneDrive - Newcastle University\\2022 to 2023\\PhD\\networkGrowth\\bikenwgrowth\\code\\functions.py:448: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  e = pd.read_csv(p + prefix + '_edges.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newcastle: Exporting simulation results to GeoJSON\n",
      "File not found for newcastle_poi_grid_closeness even after removing '_weighted', skipping to the next.\n",
      "File not found for newcastle_poi_grid_random even after removing '_weighted', skipping to the next.\n",
      "File not found for newcastle_poi_railwaystation_betweenness even after removing '_weighted', skipping to the next.\n",
      "File not found for newcastle_poi_railwaystation_closeness even after removing '_weighted', skipping to the next.\n",
      "File not found for newcastle_poi_railwaystation_random even after removing '_weighted', skipping to the next.\n",
      "File not found for newcastle_poi_neighbourhoods_closeness even after removing '_weighted', skipping to the next.\n",
      "File not found for newcastle_poi_neighbourhoods_random even after removing '_weighted', skipping to the next.\n"
     ]
    }
   ],
   "source": [
    "for placeid, placeinfo in tqdm(cities.items(), desc=\"Cities\"):\n",
    "    print(placeid + \": Exporting streets to GeoJSON\")\n",
    "    Gs = {}\n",
    "    for networktype in networktypes:\n",
    "        Gs[networktype] = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, networktype, weighting)\n",
    "        Gs[networktype + \"_simplified\"] = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, networktype + \"_simplified\", weighting)\n",
    "    for nw, G in Gs.items():\n",
    "        G_geojson = ig_to_geojson(G)\n",
    "        # Only add '_weighted' if it's not already present in the networktype\n",
    "        filename_suffix = \"_weighted\" if weighting and \"weighted\" not in nw else \"\"\n",
    "        with open(PATH[\"exports_json\"] + placeid + \"/\" + placeid + \"_\" + nw + filename_suffix + '.json', 'w') as f:\n",
    "            geojson.dump(G_geojson, f)\n",
    "    print(placeid + \": Exporting simulation results to GeoJSON\")\n",
    "    for poi_source, prune_measure in combs:\n",
    "        # Modify filename based on weighting flag\n",
    "        weighting_str = \"_weighted\" if weighting else \"\"\n",
    "        filename = placeid + '_poi_' + poi_source + \"_\" + prune_measure + weighting_str\n",
    "        try:\n",
    "            # Try loading the file with or without the \"_weighted\" suffix\n",
    "            with open(PATH[\"results\"] + placeid + \"/\" + filename + \".pickle\", 'rb') as resultfile:\n",
    "                res = pickle.load(resultfile)\n",
    "            if debug:\n",
    "                pp.pprint(res)\n",
    "\n",
    "            # Process the results\n",
    "            for GT, GT_abstract, prune_quantile in zip(res[\"GTs\"], res[\"GT_abstracts\"], res[\"prune_quantiles\"]):\n",
    "                GT_geojson = ig_to_geojson(GT)\n",
    "                \n",
    "                # Add '_weighted' only if it's not already part of the filename\n",
    "                filename_suffix = \"_weighted\" if weighting and \"weighted\" not in prune_measures[prune_measure] else \"\"\n",
    "                with open(PATH[\"exports_json\"] + placeid + \"/\" + placeid + '_GTbonly_poi_' + poi_source + \"_\" + prune_measures[prune_measure] + \"{:.3f}\".format(prune_quantile) + filename_suffix + '.json', 'w') as f:\n",
    "                    geojson.dump(GT_geojson, f)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # Attempt to load the file without the weighting suffix if it fails\n",
    "            if weighting:\n",
    "                filename = placeid + '_poi_' + poi_source + \"_\" + prune_measure\n",
    "                try:\n",
    "                    with open(PATH[\"results\"] + placeid + \"/\" + filename + \".pickle\", 'rb') as resultfile:\n",
    "                        res = pickle.load(resultfile)\n",
    "                    # Successfully loaded the file without weighting, process as normal\n",
    "                    for GT, GT_abstract, prune_quantile in zip(res[\"GTs\"], res[\"GT_abstracts\"], res[\"prune_quantiles\"]):\n",
    "                        GT_geojson = ig_to_geojson(GT)\n",
    "                        with open(PATH[\"exports_json\"] + placeid + \"/\" + placeid + '_GTbonly_poi_' + poi_source + \"_\" + prune_measures[prune_measure] + \"{:.3f}\".format(prune_quantile) + '.json', 'w') as f:\n",
    "                            geojson.dump(GT_geojson, f)\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"File not found for {filename} even after removing '_weighted', skipping to the next.\")\n",
    "            else:\n",
    "                print(f\"File not found for {filename}, skipping to the next.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting conversion of all JSON files to GeoPackages...\n",
      "All conversions completed.\n"
     ]
    }
   ],
   "source": [
    "## convert json outputs to geopackage to load into QGIS easily\n",
    "# Ensure output directory exists\n",
    "PATH['exports_gpkg'] = '../../bikenwgrowth_external/exports_gpkg/'\n",
    "output_directory = os.path.abspath(PATH['exports_gpkg'])\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Function to process each JSON file\n",
    "def process_json_file(input_file, placeid):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Check if the data is a GeometryCollection\n",
    "    if data[\"type\"] == \"GeometryCollection\":\n",
    "        # Extract only LineString geometries and create LineString objects\n",
    "        lines = [\n",
    "            LineString(g[\"coordinates\"]) for g in data[\"geometries\"] if g[\"type\"] == \"LineString\"\n",
    "        ]\n",
    "\n",
    "        # Create a GeoDataFrame from the LineStrings\n",
    "        if lines:\n",
    "            gdf_lines = gpd.GeoDataFrame(geometry=lines, crs=\"EPSG:4326\")\n",
    "            # Ensure placeid-specific output directory exists\n",
    "            place_output_directory = os.path.join(output_directory, placeid)\n",
    "            os.makedirs(place_output_directory, exist_ok=True)\n",
    "            # Save the GeoDataFrame to a GeoPackage\n",
    "            output_file_gpkg = os.path.join(place_output_directory, os.path.basename(input_file).replace(\".json\", \".gpkg\"))\n",
    "            gdf_lines.to_file(output_file_gpkg, driver='GPKG', layer='lines')\n",
    "\n",
    "            if debug:\n",
    "                print(f\"Converted {os.path.basename(input_file)} to GeoPackage and saved to {place_output_directory}\")\n",
    "\n",
    "# Function to process all JSON files in a directory\n",
    "def process_all_json_files(base_directory):\n",
    "    for root, dirs, files in os.walk(base_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                input_file = os.path.join(root, file)\n",
    "                placeid = os.path.basename(root)  # Using the name of the folder as placeid\n",
    "                if debug == True:\n",
    "                    print(f\"Processing file: {input_file} for placeid: {placeid}\")\n",
    "                process_json_file(input_file, placeid)\n",
    "\n",
    "# Specify the base directory where your JSON files are stored\n",
    "base_directory = PATH[\"exports_json\"]  # Adjust this to your base directory\n",
    "\n",
    "print(\"Starting conversion of all JSON files to GeoPackages...\")\n",
    "process_all_json_files(base_directory)\n",
    "print(\"All conversions completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Igraph picklez of simplified carconstrictedbike networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for placeid, placeinfo in tqdm(cities.items(), desc = \"Cities\"):\n",
    "    print(placeid + \": Exporting carconstrictedbike to picklez\")\n",
    "    \n",
    "    # Load existing\n",
    "    G_carall = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, 'carall')\n",
    "    with open(PATH[\"exports\"] + placeid + \"/\" + placeid + '_carall.picklez', 'wb') as f:\n",
    "        G_carall_simplified = simplify_ig(G_carall)\n",
    "        G_carall_simplified.write_picklez(fname = f)\n",
    "    if debug: map_center = nxdraw(G_carall, \"carall\")\n",
    "            \n",
    "    # Load results\n",
    "    filename = placeid + '_poi_' + poi_source + \"_\" + prune_measure\n",
    "    resultfile = open(PATH[\"results\"] + placeid + \"/\" + filename + \".pickle\",'rb')\n",
    "    res = pickle.load(resultfile)\n",
    "    resultfile.close()\n",
    "    \n",
    "    if debug:\n",
    "        fig = initplot()\n",
    "        nxdraw(G_carall_simplified, \"abstract\", map_center, nodesize = 0, weighted = True, maxwidthsquared = 500/100)\n",
    "        plt.savefig(PATH[\"exports\"] + placeid + \"/\" + placeid + '_carallweighted.png', bbox_inches=\"tight\", dpi=plotparam[\"dpi\"])\n",
    "        plt.close()\n",
    "    for GT, prune_quantile in zip(res[\"GTs\"], tqdm(res[\"prune_quantiles\"], desc = \"Growth stages\", leave = False)):\n",
    "        if prune_quantile in prune_quantiles: #[0.5,1]:\n",
    "            GT_carconstrictedbike = copy.deepcopy(G_carall)\n",
    "            constrict_overlaps(GT_carconstrictedbike, GT)\n",
    "            GT_carconstrictedbike = simplify_ig(GT_carconstrictedbike)\n",
    "            if debug:\n",
    "                fig = initplot()\n",
    "                nxdraw(GT_carconstrictedbike, \"abstract\", map_center, nodesize = 0, weighted = True, maxwidthsquared = 500)\n",
    "                plt.savefig(PATH[\"exports\"] + placeid + \"/\" + placeid + '_carconstrictedbike_poi_' + poi_source + \"_\" + prune_measures[prune_measure] + \"{:.3f}\".format(prune_quantile) + '.png', bbox_inches=\"tight\", dpi=plotparam[\"dpi\"])\n",
    "                plt.close()\n",
    "            with open(PATH[\"exports\"] + placeid + \"/\" + placeid + '_carconstrictedbike_poi_' + poi_source + \"_\" + prune_measures[prune_measure] + \"{:.3f}\".format(prune_quantile) + '.picklez', 'wb') as f:\n",
    "                GT_carconstrictedbike.write_picklez(fname = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Railwaystation POIs gdf to GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for placeid, placeinfo in tqdm(cities.items(), desc = \"Cities\"):\n",
    "    try:\n",
    "        poi_source_here = \"railwaystation\"\n",
    "        poi_gdf = gpd.GeoDataFrame.from_file(PATH[\"data\"] + placeid + \"/\" + placeid + '_' + 'poi_' + poi_source_here + '.gpkg')\n",
    "    #         pp.pprint(poi_gdf.geometry.x)\n",
    "        with open(PATH[\"exports_json\"] + placeid + \"/\" + placeid + '_poi_' + poi_source_here + '.json', 'w') as f:\n",
    "            geojson.dump(gdf_to_geojson(poi_gdf, poi_gdf.keys()), f)\n",
    "    except:\n",
    "        print(placeid + \" did not work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid and railwaystation POIs to lat/lon list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given [placeid]_poi_grid_nnidscarall, fetch and export x,y (lat,lon) from [placeid]_carall_nodes.csv to [placeid]_poi_grid_latlon.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for placeid, placeinfo in tqdm(cities.items(), desc = \"Cities\"):\n",
    "    if check_extract_zip(PATH[\"data\"] + placeid + \"/\", placeid + \"_carall\"):\n",
    "        for poi_source_here in [\"railwaystation\", \"grid\"]:\n",
    "            with open(PATH[\"data\"] + placeid + \"/\" + placeid + '_poi_' + poi_source_here + '_nnidscarall.csv', 'r') as fin, open(PATH[\"exports_json\"] + placeid + \"/\" + placeid + '_poi_' + poi_source_here + '_latlon.csv', 'w') as fout:\n",
    "            \n",
    "                fdata = np.genfromtxt(PATH[\"data\"] + placeid + \"/\" + placeid + '_carall_nodes.csv', delimiter=',', usecols=(0,1,2))\n",
    "                for line in fin:\n",
    "                    poiid = int(line.strip())\n",
    "                    fdata_lineid = np.argwhere(fdata[:, 2] == poiid)\n",
    "                    fout.write(str(fdata[fdata_lineid, 0].flatten()[0]) + \",\" + str(fdata[fdata_lineid, 1].flatten()[0]) + '\\n')\n",
    "\n",
    "        os.remove(PATH[\"data\"] + placeid + \"/\" + placeid + \"_carall_nodes.csv\")\n",
    "        os.remove(PATH[\"data\"] + placeid + \"/\" + placeid + \"_carall_edges.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoJSON Linter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://geojsonlint.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy selected videos, plots, and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyfiles = {\"plots\": \n",
    "                [\"_analysis_poi_grid_betweenness.png\",\n",
    "                 \"_analysis_poi_grid_closeness.png\",\n",
    "                 \"_analysis_poi_grid_random.png\",\n",
    "                 \"_analysis_poi_railwaystation_betweenness.png\",\n",
    "                 \"_analysis_poi_railwaystation_closeness.png\",\n",
    "                 \"_analysis_poi_railwaystation_random.png\"\n",
    "                ],\n",
    "             \"plots_networks\":\n",
    "                [\"_biketrack.pdf\",\n",
    "                 \"_bikeable.pdf\",\n",
    "                 \"_biketrackcarall.pdf\",\n",
    "                 \"_carall.pdf\",\n",
    "                 \"_carall_poi_grid.pdf\",\n",
    "                 \"_carall_poi_railwaystation.pdf\",\n",
    "                 \"_MSTabstract_poi_grid.pdf\",\n",
    "                 \"_MSTabstract_poi_railwaystation.pdf\",\n",
    "                 \"_MSTall_poi_grid.pdf\",\n",
    "                 \"_MSTall_poi_railwaystation.pdf\",\n",
    "                 \"_GTallcover_poi_grid_Bq1.000.png\",\n",
    "                 \"_GTallcover_poi_railwaystation_Bq1.000.png\"\n",
    "                ],\n",
    "            \"videos\":\n",
    "                [\"_GTabstract_poi_grid_Bq.mp4\",\n",
    "                 \"_GTabstract_poi_grid_Cq.mp4\",\n",
    "                 \"_GTabstract_poi_grid_Rq.mp4\",\n",
    "                 \"_GTabstract_poi_railwaystation_Bq.mp4\",\n",
    "                 \"_GTabstract_poi_railwaystation_Cq.mp4\",\n",
    "                 \"_GTabstract_poi_railwaystation_Rq.mp4\",\n",
    "                 \"_GTall_poi_grid_Bq.mp4\",\n",
    "                 \"_GTall_poi_grid_Cq.mp4\",\n",
    "                 \"_GTall_poi_grid_Rq.mp4\",\n",
    "                 \"_GTall_poi_railwaystation_Bq.mp4\",\n",
    "                 \"_GTall_poi_railwaystation_Cq.mp4\",\n",
    "                 \"_GTall_poi_railwaystation_Rq.mp4\",\n",
    "                 \"_GTallcover_poi_grid_Bq.mp4\",\n",
    "                 \"_GTallcover_poi_grid_Cq.mp4\",\n",
    "                 \"_GTallcover_poi_grid_Rq.mp4\",\n",
    "                 \"_GTallcover_poi_railwaystation_Bq.mp4\",\n",
    "                 \"_GTallcover_poi_railwaystation_Cq.mp4\",\n",
    "                 \"_GTallcover_poi_railwaystation_Rq.mp4\",\n",
    "                 \"_GTabstract_poi_grid_Bq.webm\",\n",
    "                 \"_GTabstract_poi_grid_Cq.webm\",\n",
    "                 \"_GTabstract_poi_grid_Rq.webm\",\n",
    "                 \"_GTabstract_poi_railwaystation_Bq.webm\",\n",
    "                 \"_GTabstract_poi_railwaystation_Cq.webm\",\n",
    "                 \"_GTabstract_poi_railwaystation_Rq.webm\",\n",
    "                 \"_GTall_poi_grid_Bq.webm\",\n",
    "                 \"_GTall_poi_grid_Cq.webm\",\n",
    "                 \"_GTall_poi_grid_Rq.webm\",\n",
    "                 \"_GTall_poi_railwaystation_Bq.webm\",\n",
    "                 \"_GTall_poi_railwaystation_Cq.webm\",\n",
    "                 \"_GTall_poi_railwaystation_Rq.webm\",\n",
    "                 \"_GTallcover_poi_grid_Bq.webm\",\n",
    "                 \"_GTallcover_poi_grid_Cq.webm\",\n",
    "                 \"_GTallcover_poi_grid_Rq.webm\",\n",
    "                 \"_GTallcover_poi_railwaystation_Bq.webm\",\n",
    "                 \"_GTallcover_poi_railwaystation_Cq.webm\",\n",
    "                 \"_GTallcover_poi_railwaystation_Rq.webm\"\n",
    "                  ],\n",
    "             \"results\":\n",
    "                [\"_existing.csv\",\n",
    "                 \"_poi_railwaystation_random.csv\",\n",
    "                 \"_poi_grid_random.csv\",\n",
    "                 \"_poi_railwaystation_closeness.csv\",\n",
    "                 \"_poi_grid_closeness.csv\",\n",
    "                 \"_poi_railwaystation_betweenness.csv\",\n",
    "                 \"_poi_grid_betweenness.csv\"\n",
    "                ]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportpath = PATH[\"exports_json\"] #\"/Users/misz/Dropbox/supervision/2021ceciliamorten_bikeviz/data/\" \n",
    "for placeid, placeinfo in tqdm(cities.items(), desc = \"Cities\"):\n",
    "    for k, v in copyfiles.items():\n",
    "        for filename in v:\n",
    "            try:\n",
    "                shutil.copy2(PATH[k] + placeid + \"/\" + placeid + filename, exportpath + placeid + \"/\")\n",
    "            except:\n",
    "                print(\"File not found: \" + placeid + filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
